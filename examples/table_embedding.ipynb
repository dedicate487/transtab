{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9aa34ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "import transtab\n",
    "\n",
    "# set random seed\n",
    "transtab.random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce7052e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/transtab/transtab/transtab/dataset.py:167: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  dataset = openml.datasets.get_dataset(dataname)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openml data index: 31\n",
      "load data from credit-g\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "free variable 'bin_cols' referenced before assignment in enclosing scope",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# load a dataset and start vanilla supervised training\u001b[39;00m\n\u001b[1;32m      2\u001b[0m allset, trainset, valset, testset, cat_cols, num_cols, bin_cols \\\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;241m=\u001b[39m \u001b[43mtranstab\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcredit-g\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/transtab/transtab/transtab/dataset.py:88\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(dataname, dataset_config, encode_cat, data_cut, seed)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# 2024年7月3日15点42分\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# isinstance(a,b): 判断a是否是b类型，返回bool类型\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataname, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# load a single tabular data\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_single_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_cat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_cat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_cut\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_cut\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataname, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# load a list of datasets, combine together and outputs\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     num_col_list, cat_col_list, bin_col_list \u001b[38;5;241m=\u001b[39m [], [], []\n",
      "File \u001b[0;32m~/transtab/transtab/transtab/dataset.py:200\u001b[0m, in \u001b[0;36mload_single_data\u001b[0;34m(dataname, dataset_config, encode_cat, data_cut, seed)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# 这步操作暂时没有效果\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: bin_cols \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 200\u001b[0m cat_cols \u001b[38;5;241m=\u001b[39m [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m cat_cols \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m bin_cols]\n\u001b[1;32m    202\u001b[0m \u001b[38;5;66;03m# encode target label（字符串标签 → 数字标签）\u001b[39;00m\n\u001b[1;32m    203\u001b[0m y \u001b[38;5;241m=\u001b[39m LabelEncoder()\u001b[38;5;241m.\u001b[39mfit_transform(y\u001b[38;5;241m.\u001b[39mvalues)\n",
      "File \u001b[0;32m~/transtab/transtab/transtab/dataset.py:200\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# 这步操作暂时没有效果\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: bin_cols \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 200\u001b[0m cat_cols \u001b[38;5;241m=\u001b[39m [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m cat_cols \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mbin_cols\u001b[49m]\n\u001b[1;32m    202\u001b[0m \u001b[38;5;66;03m# encode target label（字符串标签 → 数字标签）\u001b[39;00m\n\u001b[1;32m    203\u001b[0m y \u001b[38;5;241m=\u001b[39m LabelEncoder()\u001b[38;5;241m.\u001b[39mfit_transform(y\u001b[38;5;241m.\u001b[39mvalues)\n",
      "\u001b[0;31mNameError\u001b[0m: free variable 'bin_cols' referenced before assignment in enclosing scope"
     ]
    }
   ],
   "source": [
    "# load a dataset and start vanilla supervised training\n",
    "allset, trainset, valset, testset, cat_cols, num_cols, bin_cols \\\n",
    "    = transtab.load_data('credit-g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e709521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a fast pre-train of TransTab contrastive learning model\n",
    "# build contrastive learner, set supervised=True for supervised VPCL\n",
    "model, collate_fn = transtab.build_contrastive_learner(\n",
    "    cat_cols, num_cols, bin_cols, \n",
    "    supervised=True, # if take supervised CL\n",
    "    num_partition=4, # num of column partitions for pos/neg sampling\n",
    "    overlap_ratio=0.5, # specify the overlap ratio of column partitions during the CL\n",
    ")\n",
    "\n",
    "# start contrastive pretraining training\n",
    "training_arguments = {\n",
    "    'num_epoch':50,\n",
    "    'batch_size':64,\n",
    "    'lr':1e-4,\n",
    "    'eval_metric':'val_loss',\n",
    "    'eval_less_is_better':True,\n",
    "    'output_dir':'./checkpoint'\n",
    "    }\n",
    "\n",
    "transtab.train(model, trainset, valset, collate_fn=collate_fn, **training_arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c87e48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are two ways to build the encoder\n",
    "# First, take the whole pretrained model and output the cls token embedding at the last layer's outputs\n",
    "enc = transtab.build_encoder(\n",
    "    binary_columns=bin_cols,\n",
    "    checkpoint = './checkpoint'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8149cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then take the encoder to get the input embedding\n",
    "df = trainset[0]\n",
    "output = enc(df)\n",
    "print(output.shape)\n",
    "output[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aadae44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3e1e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second, if we only want to the embeded token level embeddings (embeddings before going to transformers)\n",
    "enc = transtab.build_encoder(\n",
    "    binary_columns=bin_cols,\n",
    "    checkpoint = './checkpoint',\n",
    "    num_layer = 0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a0172b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = enc(df)\n",
    "print(output['embedding'].shape)\n",
    "output['embedding'][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55936f1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
